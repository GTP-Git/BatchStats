

# BatchStats.py
# G
# 22JUN25
#Added Halves board stats
#Added scoring response to opening move
# Schema updated 07JUN25


'''
###############################################################
###############################################################


--- Schema Start ---
'sgs_version': (str): "1.0"
'player_names': (list, 2 items):
(str): "AI 1"
(str): "AI 2"
'sgs_initial_bag': (list, 100 items):
(str): "D"
(str): "X"
(str): "O"
    ... (and 97 more items)
'initial_racks_sgs': (list, 2 items):
(list, 7 items):
(str): "L"
(str): "A"
(str): "I"
      ... (and 4 more items)
(list, 7 items):
(str): "R"
(str): "W"
(str): "D"
      ... (and 4 more items)
'full_move_history': (list, 24 items):
    'player': (int): 1
    'move_type': (str): "place"
    'rack': (list, 7 items):
(str): "L"
(str): "A"
(str): "I"
        ... (and 4 more items)
    'score': (int): 22
    'word': (str): "JILL"
    'positions': (list, 4 items):
(tuple, 3 items):
(int): 7
(int): 7
(str): "J"
(tuple, 3 items):
(int): 7
(int): 8
(str): "I"
(tuple, 3 items):
(int): 7
(int): 9
(str): "L"
        ... (and 1 more items)
    'blanks': (set): set() (empty)
    'drawn': (list, 4 items):
(str): "T"
(str): "A"
(str): "V"
        ... (and 1 more items)
    'coord': (str): "8H"
    'word_with_blanks': (str): "JILL"
    'is_bingo': (bool): False
    'turn_duration': (float): 0.0
    'total_expected_draw_value': (float): 2.9681374511827956
    'luck_factor': (float): -14.275417451182797
    'tiles_played_from_rack': (list, 4 items):
(str): "J"
(str): "I"
(str): "L"
        ... (and 1 more items)
    'leave': (list, 3 items):
(str): "L"
(str): "A"
(str): "N"
    'newly_placed': (list, 4 items):
(tuple, 3 items):
(int): 7
(int): 7
(str): "J"
(tuple, 3 items):
(int): 7
(int): 8
(str): "I"
(tuple, 3 items):
(int): 7
(int): 9
(str): "L"
        ... (and 1 more items)
    'start': (tuple, 2 items):
(int): 7
(int): 7
    'direction': (str): "H"
    'player': (int): 2
    'move_type': (str): "place"
    'rack': (list, 7 items):
(str): "R"
(str): "W"
(str): "D"
        ... (and 4 more items)
    'score': (float): 16.0
    'word': (str): "WILD"
    'positions': (list, 4 items):
(tuple, 3 items):
(int): 5
(int): 9
(str): "W"
(tuple, 3 items):
(int): 6
(int): 9
(str): "I"
(tuple, 3 items):
(int): 7
(int): 9
(str): "L"
        ... (and 1 more items)
    'blanks': (set): set() (empty)
    'drawn': (list, 3 items):
(str): "Z"
(str): "A"
(str): "A"
    'coord': (str): "J6"
    'word_with_blanks': (str): "WILD"
    'is_bingo': (bool): False
    'turn_duration': (float): 0.0
    'total_expected_draw_value': (float): 1.5162524514606743
    'luck_factor': (float): 2.7105889485393253
    'tiles_played_from_rack': (list, 3 items):
(str): "D"
(str): "I"
(str): "W"
    'leave': (list, 4 items):
(str): "R"
(str): "S"
(str): " "
        ... (and 1 more items)
    'newly_placed': (list, 3 items):
(tuple, 3 items):
(int): 8
(int): 9
(str): "D"
(tuple, 3 items):
(int): 6
(int): 9
(str): "I"
(tuple, 3 items):
(int): 5
(int): 9
(str): "W"
    'start': (tuple, 2 items):
(int): 5
(int): 9
    'direction': (str): "V"
    'player': (int): 1
    'move_type': (str): "place"
    'rack': (list, 7 items):
(str): "A"
(str): "N"
(str): "L"
        ... (and 4 more items)
    'score': (float): 24.0
    'word': (str): "VALIANT"
    'positions': (list, 7 items):
(tuple, 3 items):
(int): 4
(int): 8
(str): "V"
(tuple, 3 items):
(int): 5
(int): 8
(str): "A"
(tuple, 3 items):
(int): 6
(int): 8
(str): "L"
        ... (and 4 more items)
    'blanks': (set): set() (empty)
    'drawn': (list, 6 items):
(str): "O"
(str): "H"
(str): "V"
        ... (and 3 more items)
    'coord': (str): "I5"
    'word_with_blanks': (str): "VALIANT"
    'is_bingo': (bool): False
    'turn_duration': (float): 0.0
    'total_expected_draw_value': (float): 5.275505839534884
    'luck_factor': (float): 12.109374160465116
    'tiles_played_from_rack': (list, 6 items):
(str): "A"
(str): "L"
(str): "A"
        ... (and 3 more items)
    'leave': (list, 1 items):
(str): "T"
    'newly_placed': (list, 6 items):
(tuple, 3 items):
(int): 8
(int): 8
(str): "A"
(tuple, 3 items):
(int): 6
(int): 8
(str): "L"
(tuple, 3 items):
(int): 5
(int): 8
(str): "A"
        ... (and 3 more items)
    'start': (tuple, 2 items):
(int): 4
(int): 8
    'direction': (str): "V"
    ... (and 21 more items)
'final_scores_adjusted': (list, 2 items):
(float): 373.0
(float): 439.0
'game_mode_info':   'game_mode_str': (str): "AI vs AI"
  'practice_mode_str': (NoneType): None
'game_settings':   'use_endgame_solver': (bool): False
  'use_ai_simulation': (bool): False
  'is_ai_config': (list, 2 items):
(bool): True
(bool): True
  'letter_checks': (list, 4 items):
(bool): True
(bool): True
(bool): True
      ... (and 1 more items)
  'number_checks': (list, 6 items):
(bool): True
(bool): True
(bool): True
      ... (and 3 more items)
  'ai_simulation_parameters':     'num_candidates': (int): 10
    'num_opponent_sims': (int): 50
    'num_post_sim_candidates': (int): 10
  'bbb_7l_max_prob': (int): 1000
  'bbb_8l_max_prob': (int): 1000
--- Schema End ---


###############################################################
###############################################################
'''


import tkinter as tk
from tkinter import filedialog, scrolledtext
import os
import pickle
import csv
import pandas as pd # For statistical analysis
import matplotlib.pyplot as plt
import subprocess
import concurrent.futures



# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- CONFIGURATION & CONSTANTS ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================

SGS_FILES_DIRECTORY = "/Users/gregmacbook/Documents/Batch Games"
OUTPUT_CSV_FILE = "batch_stats_summary.csv"
BINGO_MIN_TILES = 7 # Minimum number of tiles played to be considered a bingo

# --- Game Data Keys (based on observed .sgs file structure) ---
# These keys provide a single point of reference for the raw data structure.
# The ParsedGame class (Layer 2) will use these to abstract the data.
SGS_VERSION_KEY = 'sgs_version'
FULL_MOVE_HISTORY_KEY = 'full_move_history'
FINAL_SCORES_ADJUSTED_KEY = 'final_scores_adjusted'

MOVE_PLAYER_INDEX_KEY = 'player'
MOVE_SCORE_KEY = 'score'
MOVE_IS_BINGO_FLAG_KEY = 'is_bingo'
MOVE_TILES_PLAYED_KEY = 'tiles_played_from_rack'


# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- LAYER 1: DATA LOADING & PARSING (SGS Files -> Raw Game Object) ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================

def load_sgs_file(filename, status_widget):
    """
    Loads a complete game state from an .sgs file using pickle.
    This is our primary Layer 1 component.
    """
    try:
        with open(filename, 'rb') as f_load:
            loaded_data = pickle.load(f_load)
        # Status update is now less critical here, but can be useful for debugging.
        # update_status(status_widget, f"Successfully loaded: {os.path.basename(filename)}")

        if not isinstance(loaded_data, dict):
            if status_widget:
                update_status(status_widget, f"Error: {os.path.basename(filename)} did not load as a dictionary.")
            return None
        return loaded_data
    except FileNotFoundError:
        if status_widget:
            update_status(status_widget, f"Error: File not found '{filename}'")
        return None
    except (pickle.UnpicklingError, EOFError) as e:
        if status_widget:
            update_status(status_widget, f"Error unpickling data from {os.path.basename(filename)}: {e}")
        return None
    except Exception as e:
        if status_widget:
            update_status(status_widget, f"Unexpected error loading {os.path.basename(filename)}: {e}")
        return None


# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- LAYER 2: GAME DATA ABSTRACTION (Raw Game Object -> Structured Game Object) ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================

class ParsedGame:
    """
    A wrapper for the raw game_data dictionary loaded from an .sgs file.
    It provides a clean, stable interface for accessing game data, abstracting
    away the underlying dictionary keys.
    """
    def __init__(self, game_data, source_filename):
        self._data = game_data
        self._filename = os.path.basename(source_filename)

    def get_filename(self):
        """Returns the base filename of the source .sgs file."""
        return self._filename

    def is_valid(self):
        """
        Checks if the loaded game data contains the minimum required keys
        for basic statistical analysis.
        """
        if not self._data:
            return False
        
        final_scores = self._data.get(FINAL_SCORES_ADJUSTED_KEY)
        if final_scores is None or not isinstance(final_scores, list) or len(final_scores) < 2:
            print(f"Validation failed for {self._filename}: Missing or invalid '{FINAL_SCORES_ADJUSTED_KEY}'.")
            return False
            
        move_history = self._data.get(FULL_MOVE_HISTORY_KEY)
        if move_history is None or not isinstance(move_history, list):
            print(f"Validation failed for {self._filename}: Missing or invalid '{FULL_MOVE_HISTORY_KEY}'.")
            return False
            
        return True

    def get_final_scores(self):
        """Returns a list of final scores, e.g., [p1_score, p2_score]."""
        return self._data.get(FINAL_SCORES_ADJUSTED_KEY, [0, 0])

    def get_move_history(self):
        """Returns the full list of move dictionaries."""
        return self._data.get(FULL_MOVE_HISTORY_KEY, [])


# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- LAYER 3: STATISTIC CALCULATION ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================

class BaseStatistic:
    """
    Abstract base class for a statistic calculator.
    Defines the interface that all concrete statistic classes must implement.
    """
    def get_column_names(self):
        """Returns a list of strings for the CSV header."""
        raise NotImplementedError("Subclasses must implement this method.")

    def calculate(self, parsed_game):
        """
        Takes a ParsedGame object and returns a dictionary of
        {column_name: value}.
        """
        raise NotImplementedError("Subclasses must implement this method.")

class GameIDStatistic(BaseStatistic):
    """Calculates the Game ID."""
    def get_column_names(self):
        return ["game_id"]

    def calculate(self, parsed_game):
        return {"game_id": parsed_game.get_filename()}



#************ --- Scoring Statistics --- ************#




class PlayerScoreStatistic(BaseStatistic):
    """Calculates final scores for both players."""
    def get_column_names(self):
        return ["p1_score", "p2_score"]

    def calculate(self, parsed_game):
        scores = parsed_game.get_final_scores()
        return {"p1_score": scores[0], "p2_score": scores[1]}

class BingoCountStatistic(BaseStatistic):
    """Counts the number of bingos for each player."""
    def get_column_names(self):
        return ["p1_bingos", "p2_bingos"]

    def calculate(self, parsed_game):
        p1_bingos = 0
        p2_bingos = 0
        for move in parsed_game.get_move_history():
            if not isinstance(move, dict):
                continue

            is_bingo = move.get(MOVE_IS_BINGO_FLAG_KEY)
            player_idx = move.get(MOVE_PLAYER_INDEX_KEY)

            bingo_found = False
            if is_bingo is True:
                bingo_found = True
            elif is_bingo is None: # Fallback for older schemas
                tiles_played = move.get(MOVE_TILES_PLAYED_KEY, [])
                if isinstance(tiles_played, (list, str)) and len(tiles_played) >= BINGO_MIN_TILES:
                    bingo_found = True
            
            if bingo_found:
                if player_idx == 1:
                    p1_bingos += 1
                elif player_idx == 2:
                    p2_bingos += 1
        
        return {"p1_bingos": p1_bingos, "p2_bingos": p2_bingos}



class MaxTurnScoreStatistic(BaseStatistic):
    """Finds the single highest-scoring turn in the game."""
    def get_column_names(self):
        return ["game_max_turn_score"]

    def calculate(self, parsed_game):
        max_score = 0
        for move in parsed_game.get_move_history():
            if not isinstance(move, dict):
                continue
            
            turn_score = move.get(MOVE_SCORE_KEY, 0)
            if not isinstance(turn_score, (int, float)):
                turn_score = 0
            
            if turn_score > max_score:
                max_score = turn_score
        
        return {"game_max_turn_score": max_score}



class TurnCountStatistic(BaseStatistic):
    """Counts the number of 'place' moves for each player."""
    def get_column_names(self):
        return ["p1_turn_count", "p2_turn_count"]

    def calculate(self, parsed_game):
        p1_turns = 0
        p2_turns = 0
        for move in parsed_game.get_move_history():
            if move.get('move_type') == 'place':
                player_idx = move.get(MOVE_PLAYER_INDEX_KEY)
                if player_idx == 1:
                    p1_turns += 1
                elif player_idx == 2:
                    p2_turns += 1
        return {"p1_turn_count": p1_turns, "p2_turn_count": p2_turns}





# In "BatchStats  - F - 17JUN25 - More Quadrants":
class OpeningMoveResponseStatistic(BaseStatistic):
    """
    Analyzes the relationship between P1's opening move and P2's response.
    Specifically, it records the number of *unique* tiles in P1's opener
    and the score of P2's subsequent first move.
    """
    def get_column_names(self):
        return ["p1_opening_length", "p1_opening_unique_tiles", "p2_response_score"]

    def calculate(self, parsed_game):
        move_history = parsed_game.get_move_history()
        
        p1_first_move = None
        p2_first_move = None
        
        # Find the first 'place' move for each player
        found_p1_move = False
        for move in move_history:
            if move.get('move_type') == 'place':
                player_idx = move.get('player')
                if player_idx == 1 and not found_p1_move:
                    p1_first_move = move
                    found_p1_move = True
                elif player_idx == 2 and found_p1_move: # Ensure P2's move is after P1's
                    p2_first_move = move
                    break # We have both moves we need

        # If we don't have a valid P1 opener and P2 response, return None
        if not p1_first_move or not p2_first_move:
            return {
                "p1_opening_length": None,
                "p1_opening_unique_tiles": None, 
                "p2_response_score": None
            }

        # Calculate characteristics of P1's move
        p1_tiles_played = p1_first_move.get(MOVE_TILES_PLAYED_KEY, [])
        p1_length = len(p1_tiles_played)
        p1_unique_tiles = len(set(p1_tiles_played))
        
        # Get score for P2's move
        p2_score = p2_first_move.get(MOVE_SCORE_KEY, 0)

        return {
            "p1_opening_length": p1_length,
            "p1_opening_unique_tiles": p1_unique_tiles,
            "p2_response_score": p2_score
        }




class OpeningMoveAEINRSTResponseStatistic(BaseStatistic):
    """
    Analyzes P2's response score based on the number of unique "AEINRST"
    letters in P1's opening move.
    """
    def get_column_names(self):
        return ["p1_opening_aeinrst_count", "p2_aeinrst_response_score"]

    def calculate(self, parsed_game):
        move_history = parsed_game.get_move_history()
        
        p1_first_move = None
        p2_first_move = None
        
        # Find the first 'place' move for each player
        found_p1_move = False
        for move in move_history:
            if move.get('move_type') == 'place':
                player_idx = move.get('player')
                if player_idx == 1 and not found_p1_move:
                    p1_first_move = move
                    found_p1_move = True
                elif player_idx == 2 and found_p1_move:
                    p2_first_move = move
                    break

        if not p1_first_move or not p2_first_move:
            return {"p1_opening_aeinrst_count": None, "p2_aeinrst_response_score": None}

        # Define the target letters
        AEINRST_SET = {'A', 'E', 'I', 'N', 'R', 'S', 'T'}

        # Calculate unique AEINRST tiles for P1's move
        p1_tiles_played = p1_first_move.get(MOVE_TILES_PLAYED_KEY, [])
        p1_tiles_set = set(p1_tiles_played)
        p1_aeinrst_count = len(p1_tiles_set.intersection(AEINRST_SET))
        
        # Get score for P2's move
        p2_score = p2_first_move.get(MOVE_SCORE_KEY, 0)

        return {
            "p1_opening_aeinrst_count": p1_aeinrst_count,
            "p2_aeinrst_response_score": p2_score
        }






    



#************ --- Board Structure Statistics --- ************#



class QuadrantUsageStatistic(BaseStatistic):
    """
    Calculates the number and percentage of tiles played in each quadrant.
    Uses an inclusive counting method based on the provided logic, where tiles
    on dividing lines (but not the center) are counted in adjacent quadrants.
    Q1=TopRight, Q2=TopLeft, Q3=BottomLeft, Q4=BottomRight.
    """
    def get_column_names(self):
        return [
            'q1_count', 'q2_count', 'q3_count', 'q4_count',
            'q1_perc', 'q2_perc', 'q3_perc', 'q4_perc'
        ]

    def calculate(self, parsed_game):
        counts = {"Q1": 0, "Q2": 0, "Q3": 0, "Q4": 0}
        center_r, center_c = 7, 7
        total_tiles_placed = 0

        for move in parsed_game.get_move_history():
            # The schema uses 'positions' for placed tiles in the move history.
            if move.get('move_type') != 'place':
                continue
            
            placed_tiles = move.get('newly_placed', [])
            if not isinstance(placed_tiles, list):
                continue

            for r, c, _ in placed_tiles:
                total_tiles_placed += 1

                # Check membership for each quadrant inclusively.
                # A tile on a dividing line will be counted in two quadrants.
                if r <= center_r and c >= center_c: counts["Q1"] += 1 # Top-Right
                if r <= center_r and c <= center_c: counts["Q2"] += 1 # Top-Left
                if r >= center_r and c <= center_c: counts["Q3"] += 1 # Bottom-Left
                if r >= center_r and c >= center_c: counts["Q4"] += 1 # Bottom-Right
        
        # Calculate percentages. The denominator is the total number of physical tiles placed.
        # Note: Because of the inclusive counting, the sum of these percentages may exceed 100.
        if total_tiles_placed > 0:
            q1_perc = (counts["Q1"] / total_tiles_placed) * 100.0
            q2_perc = (counts["Q2"] / total_tiles_placed) * 100.0
            q3_perc = (counts["Q3"] / total_tiles_placed) * 100.0
            q4_perc = (counts["Q4"] / total_tiles_placed) * 100.0
        else:
            q1_perc = q2_perc = q3_perc = q4_perc = 0.0

        return {
            'q1_count': counts["Q1"],
            'q2_count': counts["Q2"],
            'q3_count': counts["Q3"],
            'q4_count': counts["Q4"],
            'q1_perc': q1_perc,
            'q2_perc': q2_perc,
            'q3_perc': q3_perc,
            'q4_perc': q4_perc,
        }




class BoardHalvesStatistic(BaseStatistic):
    """
    Calculates the number and percentage of tiles played in each half of the board.
    Uses an inclusive counting method where tiles on the center row/column are
    counted in both adjacent halves.
    """
    def get_column_names(self):
        return [
            'top_half_count', 'bottom_half_count', 'left_half_count', 'right_half_count',
            'top_half_perc', 'bottom_half_perc', 'left_half_perc', 'right_half_perc'
        ]

    def calculate(self, parsed_game):
        counts = {"top": 0, "bottom": 0, "left": 0, "right": 0}
        center_r, center_c = 7, 7
        total_tiles_placed = 0

        for move in parsed_game.get_move_history():
            if move.get('move_type') != 'place':
                continue
            
            placed_tiles = move.get('newly_placed', [])
            if not isinstance(placed_tiles, list):
                continue

            total_tiles_placed += len(placed_tiles)

            for r, c, _ in placed_tiles:
                if r <= center_r: counts["top"] += 1
                if r >= center_r: counts["bottom"] += 1
                if c <= center_c: counts["left"] += 1
                if c >= center_c: counts["right"] += 1
        
        if total_tiles_placed > 0:
            top_perc = (counts["top"] / total_tiles_placed) * 100.0
            bottom_perc = (counts["bottom"] / total_tiles_placed) * 100.0
            left_perc = (counts["left"] / total_tiles_placed) * 100.0
            right_perc = (counts["right"] / total_tiles_placed) * 100.0
        else:
            top_perc = bottom_perc = left_perc = right_perc = 0.0

        return {
            'top_half_count': counts["top"],
            'bottom_half_count': counts["bottom"],
            'left_half_count': counts["left"],
            'right_half_count': counts["right"],
            'top_half_perc': top_perc,
            'bottom_half_perc': bottom_perc,
            'left_half_perc': left_perc,
            'right_half_perc': right_perc,
        }





class OpeningMoveStatistic(BaseStatistic):
    """
    Extracts the direction of the opening move of the game.
    """
    def get_column_names(self):
        return ['opening_direction']

    def calculate(self, parsed_game):
        move_history = parsed_game.get_move_history()
        
        # Find the first 'place' move in the history
        first_place_move = None
        for move in move_history:
            if move.get('move_type') == 'place':
                first_place_move = move
                break
        
        if first_place_move:
            direction = first_place_move.get('direction', 'N/A')
        else:
            direction = 'N/A' # Game may have had no moves
            
        return {'opening_direction': direction}


    




class SquareUsageStatistic(BaseStatistic):
    """
    A stateful statistic calculator that aggregates data across all games
    and saves its result to a separate file instead of the main CSV.
    It counts the number of times each square on the board is used.
    """
    def __init__(self):
        # 15x15 grid to store counts for each square
        self.square_counts = [[0] * 15 for _ in range(15)]
        self.games_processed = 0

    def aggregate(self, other_stat):
        """Combines the results from another instance of this class."""
        if not isinstance(other_stat, SquareUsageStatistic):
            return
        self.games_processed += other_stat.games_processed
        for r in range(15):
            for c in range(15):
                self.square_counts[r][c] += other_stat.square_counts[r][c]



        

    def get_column_names(self):
        # This statistic does not add columns to the main CSV.
        return []

    def calculate(self, parsed_game):
        # This method is repurposed to process a single game and update state.
        self.games_processed += 1
        for move in parsed_game.get_move_history():
            if move.get('move_type') != 'place':
                continue
            
            placed_tiles = move.get('newly_placed', [])
            if not isinstance(placed_tiles, list):
                continue

            for r, c, _ in placed_tiles:
                if 0 <= r < 15 and 0 <= c < 15:
                    self.square_counts[r][c] += 1
        
        # Return an empty dictionary as we are not adding to the CSV row.
        return {}

    def save_results(self, output_filename="square_usage_counts.json"):
        """Saves the aggregated counts and total games to a JSON file."""
        import json
        if self.games_processed == 0:
            print("Warning: No games were processed for SquareUsageStatistic.")
            return

        data_to_save = {
            "games_processed": self.games_processed,
            "square_counts": self.square_counts
        }
        with open(output_filename, 'w') as f:
            json.dump(data_to_save, f, indent=2)
        print(f"Square usage data saved to {output_filename}")






class ComebackAnalysisStatistic(BaseStatistic):
    """
    A stateful statistic that analyzes "comeback attempts".
    It checks turns where a player is trailing by 40+ points and categorizes
    their move as either opening a new quadrant or playing in existing ones.
    It then tracks the final win rate for each strategy.
    """
    def __init__(self):
        self.open_new_quad_attempts = 0
        self.open_new_quad_wins = 0
        self.play_existing_attempts = 0
        self.play_existing_wins = 0


    def aggregate(self, other_stat):
        """Combines the results from another instance of this class."""
        if not isinstance(other_stat, ComebackAnalysisStatistic):
            return
        self.open_new_quad_attempts += other_stat.open_new_quad_attempts
        self.open_new_quad_wins += other_stat.open_new_quad_wins
        self.play_existing_attempts += other_stat.play_existing_attempts
        self.play_existing_wins += other_stat.play_existing_wins

    def get_column_names(self):
        return [] # Does not add to the main CSV

    def calculate(self, parsed_game):
        # --- Setup for a single game ---
        p1_score, p2_score = parsed_game.get_final_scores()
        p1_won_game = p1_score > p2_score
        
        p1_cumulative = 0
        p2_cumulative = 0
        active_quadrants = set()
        center_r, center_c = 7, 7

        # --- Reconstruct game turn-by-turn ---
        for move in parsed_game.get_move_history():
            if move.get('move_type') != 'place':
                continue

            player_idx = move.get('player')
            turn_score = move.get('score', 0)
            newly_placed = move.get('newly_placed', [])

            # --- Check for comeback attempt trigger ---
            is_comeback_attempt = False
            if player_idx == 1 and (p2_cumulative - p1_cumulative) >= 40:
                is_comeback_attempt = True
            elif player_idx == 2 and (p1_cumulative - p2_cumulative) >= 40:
                is_comeback_attempt = True

            if is_comeback_attempt:
                # --- Analyze the move ---
                move_quadrants = set()
                for r, c, _ in newly_placed:
                    # EXCLUSIVE counting for this analysis
                    if r < center_r and c > center_c: move_quadrants.add(1) # Top-Right
                    if r < center_r and c < center_c: move_quadrants.add(2) # Top-Left
                    if r > center_r and c < center_c: move_quadrants.add(3) # Bottom-Left
                    if r > center_r and c > center_c: move_quadrants.add(4) # Bottom-Right
                
                opened_new_quadrant = not move_quadrants.issubset(active_quadrants)
                
                if opened_new_quadrant:
                    self.open_new_quad_attempts += 1
                    if (player_idx == 1 and p1_won_game) or (player_idx == 2 and not p1_won_game):
                        self.open_new_quad_wins += 1
                else:
                    self.play_existing_attempts += 1
                    if (player_idx == 1 and p1_won_game) or (player_idx == 2 and not p1_won_game):
                        self.play_existing_wins += 1

            # --- Update state for next turn ---
            for r, c, _ in newly_placed:
                # EXCLUSIVE counting for this analysis
                if r < center_r and c > center_c: active_quadrants.add(1) # Top-Right
                if r < center_r and c < center_c: active_quadrants.add(2) # Top-Left
                if r > center_r and c < center_c: active_quadrants.add(3) # Bottom-Left
                if r > center_r and c > center_c: active_quadrants.add(4) # Bottom-Right

            if player_idx == 1:
                p1_cumulative += turn_score
            elif player_idx == 2:
                p2_cumulative += turn_score
        
        return {} # Return empty dict as we don't add to CSV

    def save_results(self, output_filename="comeback_analysis_results.json"):
        """Saves the aggregated analysis to a JSON file."""
        import json
        
        open_win_rate = (self.open_new_quad_wins / self.open_new_quad_attempts * 100) if self.open_new_quad_attempts > 0 else 0
        existing_win_rate = (self.play_existing_wins / self.play_existing_attempts * 100) if self.play_existing_attempts > 0 else 0

        results = {
            "strategy": ["Open New Quadrant", "Play in Existing Quadrants"],
            "attempts": [self.open_new_quad_attempts, self.play_existing_attempts],
            "wins": [self.open_new_quad_wins, self.play_existing_wins],
            "win_rate_percent": [open_win_rate, existing_win_rate]
        }
        with open(output_filename, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"Comeback analysis data saved to {output_filename}")





class ScoreByTilesPlayedStatistic(BaseStatistic):
    """
    A stateful statistic that aggregates scores based on the number of tiles
    played in a turn (1-7). It saves its results to a separate JSON file.
    """
    def __init__(self):
        # Key: number of tiles (1-7), Value: list of scores
        self.scores_by_tile_count = {i: [] for i in range(1, 8)}

    def aggregate(self, other_stat):
        """Combines the results from another instance of this class."""
        if not isinstance(other_stat, ScoreByTilesPlayedStatistic):
            return
        for i in range(1, 8):
            self.scores_by_tile_count[i].extend(other_stat.scores_by_tile_count[i])

    def get_column_names(self):
        return [] # Does not add to the main CSV

    def calculate(self, parsed_game):
        for move in parsed_game.get_move_history():
            if move.get('move_type') != 'place':
                continue
            
            tiles_played = move.get(MOVE_TILES_PLAYED_KEY, [])
            num_tiles = len(tiles_played)
            
            if 1 <= num_tiles <= 7:
                score = move.get(MOVE_SCORE_KEY, 0)
                if isinstance(score, (int, float)):
                    self.scores_by_tile_count[num_tiles].append(score)
        
        return {} # Return empty dict as we don't add to CSV row

    def save_results(self, output_filename="score_by_tiles_played.json"):
        """Calculates final stats and saves the aggregated data to a JSON file."""
        import json
        
        analysis_results = []
        for tile_count in range(1, 8):
            scores = self.scores_by_tile_count[tile_count]
            turn_count = len(scores)
            avg_score = sum(scores) / turn_count if turn_count > 0 else 0
            
            analysis_results.append({
                'tiles_played': tile_count,
                'turn_count': turn_count,
                'avg_score': avg_score
            })
            
        with open(output_filename, 'w') as f:
            json.dump(analysis_results, f, indent=2)
        print(f"Score by tiles played data saved to {output_filename}")


    



    

# --- Registry of all statistics to be calculated ---
STATISTICS_TO_RUN = [
    GameIDStatistic(),
    PlayerScoreStatistic(),
    BingoCountStatistic(),
    MaxTurnScoreStatistic(),
    QuadrantUsageStatistic(),
    BoardHalvesStatistic(),
    OpeningMoveStatistic(),
    TurnCountStatistic(),
    OpeningMoveResponseStatistic(),
    OpeningMoveAEINRSTResponseStatistic(),
]


# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- LAYER 4: CSV GENERATION & ORCHESTRATION ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================


def process_single_file(filepath):
    """
    Worker function that processes a single .sgs file.
    This function is executed by each parallel process.
    """
    # Note: We can't pass the status_widget to child processes.
    # Status updates will be handled differently.
    raw_game_data = load_sgs_file(filepath, None)
    if not raw_game_data:
        return None

    sgs_file = os.path.basename(filepath)
    parsed_game = ParsedGame(raw_game_data, sgs_file)
    if not parsed_game.is_valid():
        return None

    # Instantiate local statistics for this one file
    stats_to_run_for_csv = [
        GameIDStatistic(), PlayerScoreStatistic(), BingoCountStatistic(),
        MaxTurnScoreStatistic(), QuadrantUsageStatistic(), BoardHalvesStatistic(),
        OpeningMoveStatistic(), TurnCountStatistic(), OpeningMoveResponseStatistic(),
        OpeningMoveAEINRSTResponseStatistic(),
    ]
    square_usage_stat = SquareUsageStatistic()
    comeback_stat = ComebackAnalysisStatistic()
    score_by_tiles_stat = ScoreByTilesPlayedStatistic()
    
    # Calculate all stats
    game_stats_row = {}
    for stat in stats_to_run_for_csv:
        game_stats_row.update(stat.calculate(parsed_game))
    
    square_usage_stat.calculate(parsed_game)
    comeback_stat.calculate(parsed_game)
    score_by_tiles_stat.calculate(parsed_game)

    return (game_stats_row, square_usage_stat, comeback_stat, score_by_tiles_stat)





# In "BatchStats  - F - 17JUN25 - More Quadrants":
def process_all_sgs_files(directory, status_widget):
    """
    Orchestrates the entire process in parallel using a ProcessPoolExecutor.
    """
    update_status(status_widget, f"Scanning for SGS files in: {directory}")
    sgs_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(".sgs")]

    if not sgs_files:
        update_status(status_widget, "No .sgs files found in the directory.")
        return None

    all_csv_rows = []
    # Create master instances of stateful stats to aggregate into
    master_square_usage_stat = SquareUsageStatistic()
    master_comeback_stat = ComebackAnalysisStatistic()
    master_score_by_tiles_stat = ScoreByTilesPlayedStatistic()
    
    processed_count = 0
    update_status(status_widget, f"Processing {len(sgs_files)} files using multiple cores...")

    with concurrent.futures.ProcessPoolExecutor() as executor:
        # map() distributes the work and returns results as they are completed
        results = executor.map(process_single_file, sgs_files)
        
        for result in results:
            processed_count += 1
            if processed_count % 100 == 0: # Update GUI every 100 files
                update_status(status_widget, f"  ... processed {processed_count}/{len(sgs_files)} files.")

            if result:
                csv_row, square_stat, comeback_stat, score_by_tiles_stat = result
                all_csv_rows.append(csv_row)
                master_square_usage_stat.aggregate(square_stat)
                master_comeback_stat.aggregate(comeback_stat)
                master_score_by_tiles_stat.aggregate(score_by_tiles_stat)

    update_status(status_widget, f"Finished processing. Aggregating final results...")

    # --- Save aggregated results ---
    master_square_usage_stat.save_results()
    master_comeback_stat.save_results()
    master_score_by_tiles_stat.save_results()

    if not all_csv_rows:
        update_status(status_widget, "No data successfully extracted for CSV from any SGS files.")
        return False

    # --- Write to CSV ---
    try:
        # Get fieldnames from the first valid result
        fieldnames = all_csv_rows[0].keys()
        with open(OUTPUT_CSV_FILE, 'w', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_csv_rows)
        update_status(status_widget, f"Successfully wrote data for {len(all_csv_rows)} games to {OUTPUT_CSV_FILE}")
        return True
    except Exception as e:
        update_status(status_widget, f"Unexpected error writing CSV: {e}")
        return False


# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- LAYER 5: POST-CSV ANALYSIS (Pandas) ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================

def calculate_and_display_stats(status_widget):
    """
    Reads the generated CSV using Pandas and calculates/displays statistics.
    """
    try:
        df = pd.read_csv(OUTPUT_CSV_FILE)
    except FileNotFoundError:
        update_status(status_widget, f"Error: CSV file {OUTPUT_CSV_FILE} not found. Cannot calculate stats.")
        return
    except pd.errors.EmptyDataError:
        update_status(status_widget, f"Error: CSV file {OUTPUT_CSV_FILE} is empty. Cannot calculate stats.")
        return
    except Exception as e:
        update_status(status_widget, f"Error reading CSV with Pandas {OUTPUT_CSV_FILE}: {e}")
        return

    if df.empty:
        update_status(status_widget, "CSV file is empty. No statistics to calculate.")
        return

    num_games = len(df)
    update_status(status_widget, f"\n--- Statistics based on {num_games} games ---")

    # Cumulative average scores
    avg_p1_score = df['p1_score'].mean()
    avg_p2_score = df['p2_score'].mean()
    update_status(status_widget, f"Average P1 Score: {avg_p1_score:.2f}")
    update_status(status_widget, f"Average P2 Score: {avg_p2_score:.2f}")

    # Average bingos per game
    avg_p1_bingos = df['p1_bingos'].mean()
    avg_p2_bingos = df['p2_bingos'].mean()
    update_status(status_widget, f"Average P1 Bingos per Game: {avg_p1_bingos:.2f}")
    update_status(status_widget, f"Average P2 Bingos per Game: {avg_p2_bingos:.2f}")

    # Average of the "largest single score per game"
    avg_max_turn_score = df['game_max_turn_score'].mean()
    update_status(status_widget, f"Average Max Turn Score per Game: {avg_max_turn_score:.2f}")

    update_status(status_widget, "\n--- End of Statistics ---")


# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- LAYER 6: USER INTERFACE (Tkinter) & UTILITIES ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================

def update_status(text_widget, message):
    """Appends a message to the status text widget and scrolls to the end."""
    text_widget.insert(tk.END, message + "\n")
    text_widget.see(tk.END)
    text_widget.update_idletasks() # Ensure GUI updates immediately

def start_processing(status_widget):
    """Main function called when the 'Gather Stats' button is pressed."""
    status_widget.delete('1.0', tk.END) # Clear previous status messages
    update_status(status_widget, "Process started...")

    # Check if directory exists
    if not os.path.isdir(SGS_FILES_DIRECTORY):
        update_status(status_widget, f"Error: Directory not found - {SGS_FILES_DIRECTORY}")
        update_status(status_widget, "Processing aborted.")
        return

    csv_written_successfully = process_all_sgs_files(SGS_FILES_DIRECTORY, status_widget)

    if csv_written_successfully:
        calculate_and_display_stats(status_widget)
    else:
        update_status(status_widget, "CSV file was not generated or is empty. Cannot calculate statistics.")

    update_status(status_widget, "\nProcessing finished.")

def start_schema_dump(status_widget):
    """
    Handles the 'Get Schema' button click. Prompts user for an .sgs file
    and then calls dump_sgs_schema to print its structure to the console.
    """
    status_widget.insert(tk.END, "\nAttempting to dump schema...\n")
    status_widget.see(tk.END)
    
    sgs_filepath = filedialog.askopenfilename(
        title="Select an .SGS File to Analyze Schema",
        initialdir=SGS_FILES_DIRECTORY, # Start in the default batch games directory
        filetypes=(("SGS files", "*.sgs"), ("All files", "*.*"))
    )

    if sgs_filepath: # If a file was selected
        update_status(status_widget, f"Selected file for schema dump: {sgs_filepath}")
        update_status(status_widget, "Schema will be printed to the CONSOLE / TERMINAL.")
        # Call the schema dumper function (which prints to console)
        dump_sgs_schema(sgs_filepath) 
        update_status(status_widget, "Schema dump to console complete.")
    else:
        update_status(status_widget, "Schema dump cancelled (no file selected).")

def dump_sgs_schema(sgs_filepath):
    """
    Loads a single .sGS file and prints its data structure (schema)
    to the console in a human-readable format.

    Args:
        sgs_filepath (str): The full path to the .sgs file to analyze.
    """
    print(f"\n--- Analyzing schema for: {sgs_filepath} ---")
    try:
        with open(sgs_filepath, 'rb') as f_load:
            game_data = pickle.load(f_load)
    except FileNotFoundError:
        print(f"Error: File not found '{sgs_filepath}'")
        return
    except (pickle.UnpicklingError, EOFError) as e:
        print(f"Error unpickling data from {sgs_filepath}: {e}")
        return
    except Exception as e:
        print(f"Unexpected error loading {sgs_filepath}: {e}")
        return

    if not isinstance(game_data, dict):
        print(f"Error: Loaded data from {sgs_filepath} is not a dictionary (Type: {type(game_data)}). Cannot dump schema.")
        return

    print("--- Schema Start ---")
    _recursive_print_schema(game_data, indent_level=0)
    print("--- Schema End ---")

def _recursive_print_schema(data_item, indent_level=0, current_path=""):
    """
    Helper function to recursively print the schema of a data item.
    """
    indent = "  " * indent_level
    MAX_LIST_ITEMS_TO_SHOW = 3 # Show first few items of a list
    MAX_STRING_LENGTH_TO_SHOW = 70 # Truncate long strings

    if isinstance(data_item, dict):
        if not data_item:
            print(f"{indent}{current_path}(dict): {{}} (empty)")
            return
        # print(f"{indent}{current_path}(dict):") # Optional: print dict path before its items
        for key, value in data_item.items():
            new_path = f"{current_path}.{key}" if current_path else key
            print(f"{indent}'{key}': ", end="") # Print key, then let recursive call print type/value
            _recursive_print_schema(value, indent_level + 1, new_path)
    
    elif isinstance(data_item, list):
        if not data_item:
            print(f"(list): [] (empty)")
        else:
            print(f"(list, {len(data_item)} items):")
            # Show type of first item, or first few items
            for i, item in enumerate(data_item[:MAX_LIST_ITEMS_TO_SHOW]):
                item_path_display = f"{current_path}[{i}]" # For context if needed, but can be verbose
                # print(f"{indent}  [{i}]: ", end="") # Print index, then let recursive call print type/value
                _recursive_print_schema(item, indent_level + 1, item_path_display)
            if len(data_item) > MAX_LIST_ITEMS_TO_SHOW:
                print(f"{indent}  ... (and {len(data_item) - MAX_LIST_ITEMS_TO_SHOW} more items)")
    
    elif isinstance(data_item, tuple):
        if not data_item:
            print(f"(tuple): () (empty)")
        else:
            print(f"(tuple, {len(data_item)} items):")
            for i, item in enumerate(data_item[:MAX_LIST_ITEMS_TO_SHOW]):
                item_path_display = f"{current_path}[{i}]"
                _recursive_print_schema(item, indent_level + 1, item_path_display)
            if len(data_item) > MAX_LIST_ITEMS_TO_SHOW:
                print(f"{indent}  ... (and {len(data_item) - MAX_LIST_ITEMS_TO_SHOW} more items)")

    elif isinstance(data_item, set):
        if not data_item:
            print(f"(set): set() (empty)")
        else:
            # Convert set to list for consistent display of first few items
            temp_list = list(data_item)
            print(f"(set, {len(temp_list)} items): {{")
            for i, item in enumerate(temp_list[:MAX_LIST_ITEMS_TO_SHOW]):
                # Sets don't have a path for items, just show the item itself
                _recursive_print_schema(item, indent_level + 1, "") # No path for set items
            if len(temp_list) > MAX_LIST_ITEMS_TO_SHOW:
                print(f"{indent}  ... (and {len(temp_list) - MAX_LIST_ITEMS_TO_SHOW} more items)")
            print(f"{indent}}}")


    elif isinstance(data_item, str):
        if len(data_item) > MAX_STRING_LENGTH_TO_SHOW:
            print(f"(str): \"{data_item[:MAX_STRING_LENGTH_TO_SHOW]}...\" (truncated)")
        else:
            print(f"(str): \"{data_item}\"")
    
    elif isinstance(data_item, bool):
        print(f"(bool): {data_item}")
        
    elif isinstance(data_item, (int, float)):
        print(f"({type(data_item).__name__}): {data_item}")
        
    elif data_item is None:
        print(f"(NoneType): None")
        
    else:
        # For any other types, just print their type and a string representation
        print(f"({type(data_item).__name__}): {str(data_item)}")

def setup_gui():
    """Sets up and runs the Tkinter GUI."""
    root = tk.Tk()
    root.title("Scrabble Batch Stats Processor")

    main_frame = tk.Frame(root, padx=10, pady=10)
    main_frame.pack(fill=tk.BOTH, expand=True)

    # Directory Info Label
    dir_label = tk.Label(main_frame, text=f"Looking for .sgs files in: {SGS_FILES_DIRECTORY}")
    dir_label.pack(pady=(0, 10))
    
    output_csv_label = tk.Label(main_frame, text=f"Output CSV will be: {OUTPUT_CSV_FILE}")
    output_csv_label.pack(pady=(0,10))

    # Status Text Area
    status_text = scrolledtext.ScrolledText(main_frame, wrap=tk.WORD, height=20, width=80)
    status_text.pack(pady=(0, 10), fill=tk.BOTH, expand=True)

    # --- Buttons ---
    button_frame = tk.Frame(main_frame)
    button_frame.pack(fill=tk.X)

    gather_button = tk.Button(button_frame, text="Gather Stats",
                              command=lambda: start_processing(status_text))
    gather_button.pack(side=tk.LEFT, expand=True, fill=tk.X, padx=5)

    schema_button = tk.Button(button_frame, text="Get Schema from File",
                              command=lambda: start_schema_dump(status_text))
    schema_button.pack(side=tk.LEFT, expand=True, fill=tk.X, padx=5)

    report_button = tk.Button(button_frame, text="Generate Report",
                              command=lambda: start_report_generation(status_text))
    report_button.pack(side=tk.LEFT, expand=True, fill=tk.X, padx=5)
    
    update_status(status_text, "Welcome to the Scrabble Batch Stats Processor.")
    update_status(status_text, "Click 'Gather Stats' to process batch files.")
    update_status(status_text, "Click 'Get Schema from File' to analyze an .sgs file structure (output to console).")

    root.mainloop()




# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- LAYER 7: Report Generation ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================





class FootnoteManager:
    """
    A helper class to MANUALLY manage the creation and rendering of footnotes
    using HTML anchors to ensure correct placement in the final PDF.
    """
    def __init__(self):
        self._footnotes = []
        self._counter = 1

    def add_footnote(self, text):
        """
        Adds a footnote and returns an HTML superscript link to its anchor.

        Args:
            text (str): The content of the footnote.

        Returns:
            str: The HTML link, e.g., '<sup><a href="#fn1">[1]</a></sup>'.
        """
        anchor_name = f"fn{self._counter}"
        link = f'<sup><a href="#{anchor_name}">[{self._counter}]</a></sup>'
        
        # Store the text and anchor for rendering later
        self._footnotes.append({'text': text, 'anchor': anchor_name})
        
        self._counter += 1
        return link

    def render_footnotes(self):
        """
        Returns a fully formed Markdown/HTML string for the 'Notes' section.
        """
        if not self._footnotes:
            return ""
        
        # Start the section
        lines = ["\n\n---\n\n## Notes\n"]
        
        # Create a numbered list with anchors
        for i, fn in enumerate(self._footnotes):
            # The anchor is the link destination. The text is the content.
            lines.append(f"{i+1}. <a name=\"{fn['anchor']}\"></a> {fn['text']}")
            
        return "\n".join(lines)



def generate_analysis_report(status_widget):
    """
    LAYER 7: REPORT GENERATION ORCHESTRATOR
    Generates a PDF report by calling helper functions for each analysis
    section and then populating a Markdown template.
    """
    update_status(status_widget, "\n--- Starting Report Generation ---")
    
    # --- 1. Load Main Data File ---
    try:
        df = pd.read_csv(OUTPUT_CSV_FILE)
        if df.empty:
            update_status(status_widget, "Error: CSV file is empty. Cannot generate report.")
            return
    except FileNotFoundError:
        update_status(status_widget, f"Error: CSV file {OUTPUT_CSV_FILE} not found. Run 'Gather Stats' first.")
        return

    # --- 2. Run Individual Analysis Sections ---
    template_data = {}
    footnote_manager = FootnoteManager()

    score_summary_results = generate_score_summary_analysis(df, status_widget)
    if not score_summary_results: return
    template_data.update(score_summary_results)

    score_by_tiles_results = generate_score_by_tiles_played_analysis(status_widget)
    if not score_by_tiles_results: return
    template_data.update(score_by_tiles_results)

    opening_response_results = generate_opening_response_analysis(df, status_widget)
    if not opening_response_results: return
    template_data.update(opening_response_results)

    opening_aeinrst_response_results = generate_opening_aeinrst_response_analysis(df, status_widget)
    if not opening_aeinrst_response_results: return
    template_data.update(opening_aeinrst_response_results)

    opening_optimization_results = generate_opening_move_optimization_analysis(df, status_widget)
    if not opening_optimization_results: return
    template_data.update(opening_optimization_results)

    quadrant_results = generate_quadrant_analysis(df, status_widget)
    if not quadrant_results: return
    template_data.update(quadrant_results)

    quad_extremes_results = generate_quadrant_extremes_analysis(df, status_widget, footnote_manager)
    if not quad_extremes_results: return
    template_data.update(quad_extremes_results)

    board_halves_results = generate_board_halves_extremes_analysis(df, status_widget, footnote_manager)
    if not board_halves_results: return
    template_data.update(board_halves_results)

    dominant_quad_results = generate_dominant_quadrant_analysis(df, status_widget)
    if not dominant_quad_results: return
    template_data.update(dominant_quad_results)

    opening_orientation_results = generate_opening_orientation_analysis(df, status_widget)
    if not opening_orientation_results: return
    template_data.update(opening_orientation_results)

    quad_control_results = generate_quadrant_control_analysis(df, status_widget)
    if not quad_control_results: return
    template_data.update(quad_control_results)

    comeback_results = generate_comeback_analysis(status_widget)
    if not comeback_results: return
    template_data.update(comeback_results)

    heatmap_results = generate_heatmap_analysis(status_widget)
    if not heatmap_results: return
    template_data.update(heatmap_results)

    # --- 3. Load Template and Populate ---
    # THIS IS THE FIX: We add the rendered footnotes to the data dictionary
    # BEFORE formatting the template.
    template_data['final_footnotes'] = footnote_manager.render_footnotes()
    
    template_filename = "report_template.md"
    update_status(status_widget, f"Loading template file: {template_filename}...")
    try:
        with open(template_filename, 'r') as f:
            template_content = f.read()
        
        report_md_content = template_content.format(**template_data)
        
        with open("report.md", "w") as f:
            f.write(report_md_content)

    except FileNotFoundError:
        update_status(status_widget, f"ERROR: Template file '{template_filename}' not found.")
        return
    except KeyError as e:
        update_status(status_widget, f"ERROR: A placeholder {e} in the template was not provided a value.")
        return

    # --- 4. Convert to PDF using Pandoc ---
    output_pdf_filename = "Scrabble_Analysis_Report.pdf"
    update_status(status_widget, f"Converting report to PDF: {output_pdf_filename}...")
    try:
        custom_env = os.environ.copy()
        tex_path = '/Library/TeX/texbin'
        homebrew_path = '/opt/homebrew/bin'
        custom_env['PATH'] = f"{homebrew_path}{os.pathsep}{tex_path}{os.pathsep}{custom_env.get('PATH', '')}"

        subprocess.run(
            [
                'pandoc', 'report.md',
                '--pdf-engine', 'xelatex',
                '-V', 'header-includes=\\usepackage{placeins}',
                '-o', output_pdf_filename
            ],
            check=True, capture_output=True, text=True, env=custom_env
        )
        update_status(status_widget, f"SUCCESS: Report saved as {output_pdf_filename}")
    except subprocess.CalledProcessError as e:
        update_status(status_widget, "ERROR: Pandoc failed to generate PDF.")
        update_status(status_widget, f"Pandoc/XeLaTeX Error: {e.stderr}")
    except Exception as e:
        update_status(status_widget, f"An unexpected error occurred during PDF generation: {e}")



#************* --- Scoring Analysis ************* ---


def generate_score_summary_analysis(df, status_widget):
    """
    Generates the overall score summary table, narrative analysis,
    and first-player advantage text.

    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing markdown elements for the template, or None if an error occurs.
    """
    update_status(status_widget, "Generating overall score summary and analysis...")
    try:
        # --- Ensure required columns exist ---
        required_cols = ['p1_turn_count', 'p2_turn_count', 'p1_score', 'p2_score']
        if not all(col in df.columns for col in required_cols):
            update_status(status_widget, f"ERROR: CSV is missing one of {required_cols}.")
            update_status(status_widget, "Please re-run 'Gather Stats'.")
            return None

        # --- Pre-calculation for Wins and Margin ---
        df['score_diff'] = df['p1_score'] - df['p2_score']
        df['p1_wins'] = df['score_diff'] > 0
        
        # --- Calculate Primary Metrics ---
        p1_win_count = df['p1_wins'].sum()
        p2_win_count = len(df) - p1_win_count
        total_games = len(df)
        p1_win_pct = (p1_win_count / total_games) * 100 if total_games > 0 else 0
        p2_win_pct = 100 - p1_win_pct

        p1_avg_diff = df['score_diff'].mean()
        p2_avg_diff = -p1_avg_diff

        avg_p1_score = df['p1_score'].mean()
        avg_p2_score = df['p2_score'].mean()
        avg_p1_turns = df['p1_turn_count'].mean()
        avg_p2_turns = df['p2_turn_count'].mean()

        total_p1_score = df['p1_score'].sum()
        total_p2_score = df['p2_score'].sum()
        total_p1_turns = df['p1_turn_count'].sum()
        total_p2_turns = df['p2_turn_count'].sum()

        avg_p1_score_per_turn = total_p1_score / total_p1_turns if total_p1_turns > 0 else 0
        avg_p2_score_per_turn = total_p2_score / total_p2_turns if total_p2_turns > 0 else 0

        # --- Create the Main Summary Markdown Table ---
        summary_df = pd.DataFrame({
            'Metric': [
                'Win Percentage',
                'Avg. Score Differential',
                'Average Score',
                'Average Turns per Game',
                'Average Score per Turn'
            ],
            'Player 1 (First)': [p1_win_pct, p1_avg_diff, avg_p1_score, avg_p1_turns, avg_p1_score_per_turn],
            'Player 2 (Second)': [p2_win_pct, p2_avg_diff, avg_p2_score, avg_p2_turns, avg_p2_score_per_turn]
        })
        summary_table_md = summary_df.to_markdown(index=False, floatfmt=".2f")

        # --- Create the Margin of Victory/Defeat Table ---
        p1_avg_mov = df[df['p1_wins']]['score_diff'].mean() if p1_win_count > 0 else 0
        p2_avg_mov = -df[~df['p1_wins']]['score_diff'].mean() if p2_win_count > 0 else 0
        
        mov_df = pd.DataFrame({
            'Metric': ["Avg. Margin of Victory", "Avg. Margin of Defeat"],
            'Player 1': [p1_avg_mov, p2_avg_mov],
            'Player 2': [p2_avg_mov, p1_avg_mov]
        })
        mov_table_md = mov_df.to_markdown(index=False, floatfmt=".2f")

        # --- Generate Narrative Analysis ---
        score_advantage = avg_p1_score - avg_p2_score
        turn_advantage = avg_p1_turns - avg_p2_turns
        turn_advantage_value = turn_advantage * avg_p1_score_per_turn
        
        if score_advantage > 0:
            turn_advantage_contribution_pct = (turn_advantage_value / score_advantage) * 100
        else:
            turn_advantage_contribution_pct = 0

        # THIS IS THE FIX: Build the text as a list of paragraphs and join with newlines.
        # This ensures Markdown, not LaTeX, handles paragraph breaks.
        narrative_paragraphs = []
        narrative_paragraphs.append(
            f"Player 1 wins **{p1_win_pct:.2f}%** of games, demonstrating a clear first-player advantage. "
            f"The final average score advantage for Player 1 is **{score_advantage:.2f}** points."
        )
        narrative_paragraphs.append(
            f"A key driver of this is the structural turn advantage: Player 1 gets an average of **{turn_advantage:.2f}** more turns per game. "
            f"Valued at Player 1's average of **{avg_p1_score_per_turn:.2f}** points per turn, this extra play opportunity should theoretically "
            f"provide an advantage of **{turn_advantage_value:.2f}** points. "
            f"This indicates that the turn advantage alone accounts for **{turn_advantage_contribution_pct:.2f}%** of the final score difference."
        )
        
        mov_difference = p1_avg_mov - p2_avg_mov
        narrative_paragraphs.append(
            f"Player 1's average margin of victory is **{p1_avg_mov:.2f}** points. "
            f"Player 2's average margin of victory is **{p2_avg_mov:.2f}** points. "
            f"The difference is **{mov_difference:.2f}** points."
        )
        
        narrative_paragraphs.append(
            "The key takeaway is that the game is not just tilted in P1's favor in terms of frequency of wins, "
            "but also in the quality of those wins. A win by the first player is, on average, a more dominant "
            "performance than a win by the second player. Player 2 has to work harder and play more efficiently "
            "just to eke out a victory, which is reflected in their smaller average winning margin."
        )
        
        # Join paragraphs with two newlines for proper Markdown paragraph separation.
        narrative_text = "\n\n".join(narrative_paragraphs)

        update_status(status_widget, "Score summary and analysis complete.")
        return {
            'score_summary_table': summary_table_md,
            'margin_of_victory_table': mov_table_md,
            'score_summary_narrative': narrative_text
        }
    except Exception as e:
        update_status(status_widget, f"ERROR during score summary analysis: {e}")
        return None




def generate_score_by_tiles_played_analysis(status_widget):
    """
    Generates an analysis of scores based on the number of tiles played per turn.
    
    Args:
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing the markdown table and chart path for the template,
        or None if an error occurs.
    """
    import json
    
    update_status(status_widget, "Generating score by tiles played analysis...")
    try:
        json_filename = "score_by_tiles_played.json"
        chart_filename = "score_by_tiles_played_chart.png"

        with open(json_filename, 'r') as f:
            data = json.load(f)
        
        df = pd.DataFrame(data)
        
        # --- Generate Table ---
        table_df = df.copy()
        table_df.rename(columns={
            'tiles_played': 'Number of Tiles Played',
            'turn_count': 'Total Turns',
            'avg_score': 'Average Score'
        }, inplace=True)
        # Format turn_count with commas for readability
        table_df['Total Turns'] = table_df['Total Turns'].apply(lambda x: f"{x:,}")
        table_md = table_df.to_markdown(index=False, floatfmt=".2f")
        
        # --- Generate Bar Chart ---
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(df['tiles_played'], df['avg_score'], color='skyblue')
        
        ax.set_xlabel('Number of Tiles Played in Turn')
        ax.set_ylabel('Average Score')
        ax.set_title('Average Score by Number of Tiles Played')
        ax.set_xticks(df['tiles_played']) # Ensure ticks are 1, 2, 3...7
        ax.grid(axis='y', linestyle='--', alpha=0.7)
        
        plt.savefig(chart_filename)
        plt.close(fig)
        
        update_status(status_widget, "Score by tiles played analysis complete.")
        return {
            'score_by_tiles_played_table': table_md,
            'score_by_tiles_played_chart_path': chart_filename
        }

    except FileNotFoundError:
        update_status(status_widget, f"ERROR: Data file '{json_filename}' not found.")
        update_status(status_widget, "Please re-run 'Gather Stats' to generate it.")
        return None
    except Exception as e:
        update_status(status_widget, f"ERROR during score by tiles played analysis: {e}")
        return None





def generate_opening_response_analysis(df, status_widget):
    """
    Analyzes P2's response score based on the number of unique tiles
    in P1's opening move.

    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing markdown elements for the template, or None if an error occurs.
    """
    update_status(status_widget, "Generating opening move response analysis...")
    try:
        chart_filename = "opening_response_chart.png"
        required_cols = ['p1_opening_unique_tiles', 'p2_response_score']
        if not all(col in df.columns for col in required_cols):
            update_status(status_widget, f"ERROR: CSV is missing one of {required_cols}.")
            update_status(status_widget, "Please re-run 'Gather Stats'.")
            return None

        # Filter out games where P1 or P2 passed/exchanged their first move
        analysis_df = df.dropna(subset=required_cols)
        analysis_df['p1_opening_unique_tiles'] = analysis_df['p1_opening_unique_tiles'].astype(int)

        if analysis_df.empty:
            update_status(status_widget, "No valid games found for opening response analysis.")
            return {
                'opening_response_table': "No valid games found for this analysis.",
                'opening_response_chart_path': ""
            }

        # Group by the number of unique tiles and calculate stats
        grouped = analysis_df.groupby('p1_opening_unique_tiles')['p2_response_score'].agg(['mean', 'count']).reset_index()
        grouped.rename(columns={
            'p1_opening_unique_tiles': "P1's Unique Opening Tiles",
            'mean': 'Avg. P2 Response Score',
            'count': 'Game Count'
        }, inplace=True)

        # --- Generate Table ---
        table_md = grouped.to_markdown(index=False, floatfmt=".2f")

        # --- Generate Bar Chart ---
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(grouped["P1's Unique Opening Tiles"], grouped['Avg. P2 Response Score'], color='coral')
        
        ax.set_xlabel("Number of Unique Tiles in P1's Opening Move")
        ax.set_ylabel("Average Score of P2's First Move")
        ax.set_title("P2's Response Score vs. Complexity of P1's Opener")
        ax.set_xticks(grouped["P1's Unique Opening Tiles"])
        ax.grid(axis='y', linestyle='--', alpha=0.7)
        
        plt.savefig(chart_filename)
        plt.close(fig)

        update_status(status_widget, "Opening move response analysis complete.")
        return {
            'opening_response_table': table_md,
            'opening_response_chart_path': chart_filename
        }

    except Exception as e:
        update_status(status_widget, f"ERROR during opening move response analysis: {e}")
        return None




def generate_opening_aeinrst_response_analysis(df, status_widget):
    """
    Analyzes P2's response score based on the number of unique AEINRST
    letters in P1's opening move.

    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing markdown elements for the template, or None if an error occurs.
    """
    update_status(status_widget, "Generating opening move AEINRST response analysis...")
    try:
        chart_filename = "opening_aeinrst_response_chart.png"
        required_cols = ['p1_opening_aeinrst_count', 'p2_aeinrst_response_score']
        if not all(col in df.columns for col in required_cols):
            update_status(status_widget, f"ERROR: CSV is missing one of {required_cols}.")
            update_status(status_widget, "Please re-run 'Gather Stats'.")
            return None

        # Filter out games where P1 or P2 passed/exchanged their first move
        analysis_df = df.dropna(subset=required_cols)
        analysis_df['p1_opening_aeinrst_count'] = analysis_df['p1_opening_aeinrst_count'].astype(int)

        if analysis_df.empty:
            update_status(status_widget, "No valid games found for AEINRST response analysis.")
            return {
                'opening_aeinrst_response_table': "No valid games found for this analysis.",
                'opening_aeinrst_response_chart_path': ""
            }

        # Group by the number of unique tiles and calculate stats
        grouped = analysis_df.groupby('p1_opening_aeinrst_count')['p2_aeinrst_response_score'].agg(['mean', 'count']).reset_index()
        grouped.rename(columns={
            'p1_opening_aeinrst_count': "P1's Unique AEINRST Tiles",
            'mean': 'Avg. P2 Response Score',
            'count': 'Game Count'
        }, inplace=True)

        # --- Generate Table ---
        table_md = grouped.to_markdown(index=False, floatfmt=".2f")

        # --- Generate Bar Chart ---
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(grouped["P1's Unique AEINRST Tiles"], grouped['Avg. P2 Response Score'], color='mediumseagreen')
        
        ax.set_xlabel("Number of Unique AEINRST Tiles in P1's Opening Move")
        ax.set_ylabel("Average Score of P2's First Move")
        ax.set_title("P2's Response Score vs. AEINRST Tiles in P1's Opener")
        ax.set_xticks(range(0, 8)) # Ensure ticks are 0, 1, 2...7
        ax.grid(axis='y', linestyle='--', alpha=0.7)
        
        plt.savefig(chart_filename)
        plt.close(fig)

        update_status(status_widget, "Opening move AEINRST response analysis complete.")
        return {
            'opening_aeinrst_response_table': table_md,
            'opening_aeinrst_response_chart_path': chart_filename
        }

    except Exception as e:
        update_status(status_widget, f"ERROR during opening move AEINRST response analysis: {e}")
        return None




def generate_opening_move_optimization_analysis(df, status_widget):
    """
    Identifies the optimal opening move characteristics to minimize P2's response score.

    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing markdown elements for the template, or None if an error occurs.
    """
    update_status(status_widget, "Generating opening move optimization analysis...")
    try:
        MIN_GAMES_THRESHOLD = 10 # Minimum occurrences to be considered statistically significant
        
        required_cols = [
            'p1_opening_length', 'p1_opening_unique_tiles', 
            'p1_opening_aeinrst_count', 'p2_response_score'
        ]
        if not all(col in df.columns for col in required_cols):
            update_status(status_widget, f"ERROR: CSV is missing one of {required_cols}.")
            update_status(status_widget, "Please re-run 'Gather Stats'.")
            return None

        # Filter for valid games and ensure correct types
        analysis_df = df.dropna(subset=required_cols).copy()
        for col in required_cols:
            if col != 'p2_response_score':
                 analysis_df[col] = analysis_df[col].astype(int)

        if analysis_df.empty:
            update_status(status_widget, "No valid games found for opening move optimization.")
            return {'best_openers_table': "No data.", 'worst_openers_table': "No data.", 'opening_optimization_narrative': "Not enough data."}

        # Group by all three P1 move characteristics
        grouped = analysis_df.groupby([
            'p1_opening_length', 
            'p1_opening_unique_tiles', 
            'p1_opening_aeinrst_count'
        ])['p2_response_score'].agg(['mean', 'count']).reset_index()

        # Filter for significance
        significant_openers = grouped[grouped['count'] >= MIN_GAMES_THRESHOLD].copy()

        if significant_openers.empty:
            update_status(status_widget, f"No opening types met the {MIN_GAMES_THRESHOLD} game threshold.")
            return {'best_openers_table': "No data.", 'worst_openers_table': "No data.", 'opening_optimization_narrative': "Not enough data."}

        # --- Find Best and Worst Openers ---
        significant_openers.sort_values('mean', ascending=True, inplace=True)
        
        best_openers = significant_openers.head(10)
        worst_openers = significant_openers.tail(10).sort_values('mean', ascending=False)

        # --- Format Tables for Report ---
        col_rename_map = {
            'p1_opening_length': 'Length',
            'p1_opening_unique_tiles': 'Unique Tiles',
            'p1_opening_aeinrst_count': 'AEINRST Count',
            'mean': 'Avg. P2 Score',
            'count': 'Game Count'
        }
        best_openers_tbl = best_openers.rename(columns=col_rename_map)
        worst_openers_tbl = worst_openers.rename(columns=col_rename_map)

        best_md = best_openers_tbl.to_markdown(index=False, floatfmt=".2f")
        worst_md = worst_openers_tbl.to_markdown(index=False, floatfmt=".2f")

        # --- Generate Narrative ---
        narrative = (
            f"The analysis reveals distinct patterns. The best opening moves (those that minimize Player 2's response) "
            f"tend to be shorter, often using fewer unique tiles. Conversely, the moves that give Player 2 the highest-scoring "
            f"responses are typically longer plays, including bingos (7-tile plays), which open up the board significantly. "
            f"This suggests a trade-off: a high-scoring opening for Player 1 may come at the cost of creating a high-scoring "
            f"opportunity for Player 2."
        )

        update_status(status_widget, "Opening move optimization analysis complete.")
        return {
            'best_openers_table': best_md,
            'worst_openers_table': worst_md,
            'opening_optimization_narrative': narrative
        }

    except Exception as e:
        update_status(status_widget, f"ERROR during opening move optimization analysis: {e}")
        return None




#************* --- Quadrant Analysis ************* ---


def generate_quadrant_analysis(df, status_widget):
    """
    Generates the quadrant analysis table and chart.
    
    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing the markdown table and chart path for the template,
        or None if an error occurs.
    """
    update_status(status_widget, "Generating quadrant analysis...")
    try:
        quadrant_chart_filename = "quadrant_usage_chart.png"
        
        quadrant_cols = ['q1_perc', 'q2_perc', 'q3_perc', 'q4_perc']
        avg_percentages = df[quadrant_cols].mean().reset_index()
        avg_percentages.columns = ['Quadrant', 'Average Percentage']
        avg_percentages['Quadrant'] = ['Q1 (Top-Right)', 'Q2 (Top-Left)', 'Q3 (Bottom-Left)', 'Q4 (Bottom-Right)']
        
        table_md = avg_percentages.to_markdown(index=False, floatfmt=".2f")
        
        fig, ax = plt.subplots()
        ax.bar(avg_percentages['Quadrant'], avg_percentages['Average Percentage'])
        ax.set_ylabel('Average Percentage of Tiles Played (%)')
        ax.set_title('Average Quadrant Usage Across All Games')
        plt.savefig(quadrant_chart_filename)
        plt.close(fig)
        
        update_status(status_widget, "Quadrant analysis complete.")
        return {
            'quadrant_table': table_md,
            'quadrant_chart_path': quadrant_chart_filename
        }
    except Exception as e:
        update_status(status_widget, f"ERROR during quadrant analysis: {e}")
        return None




def generate_heatmap_analysis(status_widget):
    """
    Generates the square usage heatmap.
    
    Args:
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing the heatmap image path for the template,
        or None if an error occurs.
    """
    import json
    import seaborn as sns
    import pandas as pd

    
    update_status(status_widget, "Generating square usage heatmap...")
    try:
        heatmap_filename = "square_usage_heatmap.png"
        square_counts_filename = "square_usage_counts.json"

        with open(square_counts_filename, 'r') as f:
            heatmap_data = json.load(f)
        
        counts = heatmap_data['square_counts']
        num_games = heatmap_data['games_processed']
        
        if num_games == 0:
            update_status(status_widget, "Warning: 0 games processed, cannot generate heatmap.")
            return None
            

        # Calculate percentages
        percentages = [[(count / num_games) * 100 for count in row] for row in counts]
        
        # Create custom labels for the axes
        row_labels = [str(i) for i in range(1, 16)] # '1' through '15'
        col_labels = list('ABCDEFGHIJKLMNO')       # 'A' through 'O'

        # Create a Pandas DataFrame with the data and custom labels
        df_heatmap = pd.DataFrame(percentages, index=row_labels, columns=col_labels)
        
        fig, ax = plt.subplots(figsize=(12, 10))
        # Pass the DataFrame to seaborn; it will use the index/columns for labels
        sns.heatmap(df_heatmap, annot=True, fmt=".1f", cmap="viridis", linewidths=.5, ax=ax)
        ax.set_title('Heatmap of Square Usage Frequency (%)')
        ax.set_xlabel('Column')
        ax.set_ylabel('Row')
        plt.savefig(heatmap_filename)
        plt.close(fig)
        
        update_status(status_widget, "Heatmap analysis complete.")
        return {'heatmap_path': heatmap_filename}
        
    except FileNotFoundError:
        update_status(status_widget, f"ERROR: Heatmap data file '{square_counts_filename}' not found.")
        update_status(status_widget, "Run 'Gather Stats' to generate it.")
        return None
    except Exception as e:
        update_status(status_widget, f"ERROR during heatmap analysis: {e}")
        return None





def generate_dominant_quadrant_analysis(df, status_widget):
    """
    Analyzes if dominating a quadrant correlates with average scores.
    
    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing the markdown table and chart path for the template,
        or None if an error occurs.
    """
    import numpy as np

    update_status(status_widget, "Analyzing scores by dominant quadrant...")
    try:
        chart_filename = "dominant_quadrant_scores_chart.png"
        quad_count_cols = ['q1_count', 'q2_count', 'q3_count', 'q4_count']

        # For each row (game), find the column name with the maximum count.
        # This determines the dominant quadrant for that game.
        df['dominant_quadrant'] = df[quad_count_cols].idxmax(axis=1)
        
        # Group by the new 'dominant_quadrant' column and calculate average scores
        grouped_scores = df.groupby('dominant_quadrant')[['p1_score', 'p2_score']].mean()
        grouped_scores.rename(columns={
            'p1_score': 'Average P1 Score',
            'p2_score': 'Average P2 Score'
        }, inplace=True)
        
        # --- Generate Table ---
        # Create a DataFrame for the table
        table_df = grouped_scores.reset_index()

        # 1. Rename the column header from 'dominant_quadrant'
        table_df.rename(columns={'dominant_quadrant': 'Dominant Quadrant'}, inplace=True)

        # 2. Create a mapping for the row values and apply it
        quadrant_name_map = {
            'q1_count': 'Q1',
            'q2_count': 'Q2',
            'q3_count': 'Q3',
            'q4_count': 'Q4'
        }
        table_df['Dominant Quadrant'] = table_df['Dominant Quadrant'].map(quadrant_name_map)

        # Convert the cleaned-up DataFrame to Markdown
        table_md = table_df.to_markdown(index=False, floatfmt=".2f")
        
        # --- Generate Grouped Bar Chart ---
        labels = [f"Q{i+1}" for i in range(4)] # Q1, Q2, Q3, Q4
        p1_scores = grouped_scores.loc[[f'q{i+1}_count' for i in range(4)], 'Average P1 Score']
        p2_scores = grouped_scores.loc[[f'q{i+1}_count' for i in range(4)], 'Average P2 Score']

        x = np.arange(len(labels))  # the label locations
        width = 0.35  # the width of the bars

        fig, ax = plt.subplots(figsize=(10, 6))
        rects1 = ax.bar(x - width/2, p1_scores, width, label='P1 Avg Score')
        rects2 = ax.bar(x + width/2, p2_scores, width, label='P2 Avg Score')

        # Add some text for labels, title and axes ticks
        ax.set_ylabel('Average Score')
        ax.set_title('Average Scores by Dominant Quadrant')
        ax.set_xticks(x)
        ax.set_xticklabels(labels)
        ax.legend()

        fig.tight_layout()
        plt.savefig(chart_filename)
        plt.close(fig)
        
        update_status(status_widget, "Dominant quadrant analysis complete.")
        return {
            'dominant_quad_table': table_md,
            'dominant_quad_chart_path': chart_filename
        }

    except Exception as e:
        update_status(status_widget, f"ERROR during dominant quadrant analysis: {e}")
        return None






def generate_opening_orientation_analysis(df, status_widget):
    """
    Analyzes quadrant usage based on the opening move's orientation.
    
    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing the markdown table for the template,
        or None if an error occurs.
    """
    update_status(status_widget, "Analyzing quadrant usage by opening orientation...")
    try:
        if 'opening_direction' not in df.columns:
            update_status(status_widget, "ERROR: 'opening_direction' column not found in CSV.")
            update_status(status_widget, "Please re-run 'Gather Stats' to add it.")
            return None

        quad_perc_cols = ['q1_perc', 'q2_perc', 'q3_perc', 'q4_perc']
        
        # Group by opening direction and calculate the mean of the percentage columns
        grouped_data = df.groupby('opening_direction')[quad_perc_cols].mean()

        # Clean up the table for presentation
        grouped_data.rename(columns={
            'q1_perc': 'Q1 %', 'q2_perc': 'Q2 %',
            'q3_perc': 'Q3 %', 'q4_perc': 'Q4 %'
        }, inplace=True)
        
        orientation_map = {'H': 'Horizontal', 'V': 'Vertical'}
        grouped_data.index = grouped_data.index.map(orientation_map)
        grouped_data.rename_axis('Opening Orientation', inplace=True)
        
        # Convert the final, styled DataFrame to a Markdown table
        table_md = grouped_data.reset_index().to_markdown(index=False, floatfmt=".2f")

        update_status(status_widget, "Opening orientation analysis complete.")
        return {'opening_orientation_table': table_md}

    except Exception as e:
        update_status(status_widget, f"ERROR during opening orientation analysis: {e}")
        return None





def generate_quadrant_control_analysis(df, status_widget):
    """
    Analyzes if concentrating play in a few quadrants correlates with winning.
    Uses the Herfindahl-Hirschman Index (HHI) as a measure of concentration.
    
    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing the markdown table and chart path for the template,
        or None if an error occurs.
    """


    import seaborn as sns

    
    update_status(status_widget, "Analyzing quadrant control strategy...")
    try:
        chart_filename = "quadrant_control_chart.png"
        quad_count_cols = ['q1_count', 'q2_count', 'q3_count', 'q4_count']

        # --- Calculate HHI for each game ---
        # HHI = sum of squared shares. Ranges from 0.25 (balanced) to 1.0 (concentrated).
        total_counts = df[quad_count_cols].sum(axis=1)
        # Avoid division by zero for games with no moves
        total_counts[total_counts == 0] = 1 
        
        shares = df[quad_count_cols].div(total_counts, axis=0)
        squared_shares = shares.pow(2)
        df['hhi_score'] = squared_shares.sum(axis=1)

        # --- Generate Scatter Plot ---
        df['score_differential'] = df['p1_score'] - df['p2_score']
        df['p1_win'] = df['score_differential'] > 0

        fig, ax = plt.subplots(figsize=(10, 6))
        sns.regplot(
            data=df,
            x='hhi_score',
            y='score_differential',
            ax=ax,
            scatter_kws={'alpha': 0.5},  # Make points semi-transparent
            line_kws={'color': 'red', 'linestyle': '--'} # Style the trend line
        )

        ax.set_title('Quadrant Concentration (HHI) vs. Score Differential')
        ax.set_xlabel('Concentration Score (HHI) -> More Concentrated')
        ax.set_ylabel('Final Score Differential (P1 - P2)')
        ax.grid(True)
        plt.savefig(chart_filename)
        plt.close(fig)

        # --- Generate Binned Table ---
        # Bin the HHI scores into categories
        bins = [0.24, 0.33, 0.5, 1.01]
        labels = ['Balanced (Spread Out)', 'Moderate Concentration', 'Highly Concentrated']
        df['concentration_strategy'] = pd.cut(df['hhi_score'], bins=bins, labels=labels)

        # Calculate P1 win percentage for each strategy
        win_rate_by_strategy = df.groupby('concentration_strategy', observed=False)['p1_win'].value_counts(normalize=True).unstack()
        # Ensure a 'True' column exists even if no wins in a category
        if True not in win_rate_by_strategy.columns:
            win_rate_by_strategy[True] = 0
        
        win_rate_by_strategy['P1 Win %'] = win_rate_by_strategy[True].fillna(0) * 100
        
        table_df = win_rate_by_strategy[['P1 Win %']].reset_index()
        table_df.rename(columns={'concentration_strategy': 'Quadrant Strategy'}, inplace=True)
        table_md = table_df.to_markdown(index=False, floatfmt=".2f")

        update_status(status_widget, "Quadrant control analysis complete.")
        return {
            'quad_control_table': table_md,
            'quad_control_chart_path': chart_filename
        }

    except Exception as e:
        update_status(status_widget, f"ERROR during quadrant control analysis: {e}")
        return None





def generate_comeback_analysis(status_widget):
    """
    Generates the comeback analysis table from its dedicated JSON file.
    
    Args:
        status_widget: The tkinter widget for status updates.

    Returns:
        A dictionary containing the markdown table for the template,
        or None if an error occurs.
    """
    import json
    
    update_status(status_widget, "Generating comeback strategy analysis...")
    try:
        results_filename = "comeback_analysis_results.json"
        with open(results_filename, 'r') as f:
            data = json.load(f)
        
        # Convert the loaded JSON data into a Pandas DataFrame for easy table creation
        df = pd.DataFrame(data)
        df.rename(columns={
            'strategy': 'Comeback Strategy',
            'attempts': 'Total Attempts',
            'wins': 'Total Wins',
            'win_rate_percent': 'Win Rate %'
        }, inplace=True)

        table_md = df.to_markdown(index=False, floatfmt=".2f")
        
        update_status(status_widget, "Comeback analysis complete.")
        return {'comeback_table': table_md}

    except FileNotFoundError:
        update_status(status_widget, f"ERROR: Comeback analysis file '{results_filename}' not found.")
        update_status(status_widget, "Please re-run 'Gather Stats' to generate it.")
        return None
    except Exception as e:
        update_status(status_widget, f"ERROR during comeback analysis: {e}")
        return None



def generate_quadrant_extremes_analysis(df, status_widget, footnote_manager):
    """
    Generates a table, a box plot, and a single comprehensive footnote for
    the min/max quadrant usage and their source games.

    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.
        footnote_manager (FootnoteManager): The manager for creating footnotes.

    Returns:
        A dictionary containing markdown elements for the template, or None if an error occurs.
    """
    import seaborn as sns

    update_status(status_widget, "Generating quadrant extremes analysis with single footnote...")
    try:
        chart_filename = "quadrant_distribution_chart.png"
        quad_info = {
            'q1_perc': 'Q1 (Top-Right)', 'q2_perc': 'Q2 (Top-Left)',
            'q3_perc': 'Q3 (Bottom-Left)', 'q4_perc': 'Q4 (Bottom-Right)'
        }
        quad_perc_cols = list(quad_info.keys())

        # --- Generate the simple table using to_markdown ---
        mins = df[quad_perc_cols].min()
        maxs = df[quad_perc_cols].max()
        table_df = pd.DataFrame({
            'Quadrant': list(quad_info.values()),
            'Min Usage (%)': mins.values,
            'Max Usage (%)': maxs.values
        })
        table_md = table_df.to_markdown(index=False, floatfmt=".2f")

        # --- Find all source games and build a single footnote string ---
        footnote_lines = []
        for col, name in quad_info.items():
            min_idx = df[col].idxmin()
            min_game = df.loc[min_idx, 'game_id']
            # THIS IS THE FIX: Start each line with a pipe for a Markdown line block
            footnote_lines.append(f"| Min usage for {name.split(' ')[0]}: **{min_game}**")

            max_idx = df[col].idxmax()
            max_game = df.loc[max_idx, 'game_id']
            footnote_lines.append(f"| Max usage for {name.split(' ')[0]}: **{max_game}**")
        
        # Start with a newline, then join with newlines.
        full_footnote_text = "\n" + "\n".join(footnote_lines)
        footnote_ref = footnote_manager.add_footnote(full_footnote_text)

        # --- Generate Box Plot Chart (no changes here) ---
        df_long = df[quad_perc_cols].melt(var_name='Quadrant', value_name='Usage Percentage')
        quadrant_map = {k: v.split(' ')[0] for k, v in quad_info.items()}
        df_long['Quadrant'] = df_long['Quadrant'].map(quadrant_map)

        fig, ax = plt.subplots(figsize=(10, 6))
        sns.boxplot(x='Quadrant', y='Usage Percentage', data=df_long, ax=ax)
        ax.set_title('Distribution of Quadrant Usage Across All Games')
        ax.set_ylabel('Percentage of Tiles Played in Quadrant (%)')
        ax.set_xlabel('Quadrant')
        ax.grid(axis='y', linestyle='--', alpha=0.7)
        plt.savefig(chart_filename)
        plt.close(fig)

        update_status(status_widget, "Quadrant extremes analysis complete.")
        return {
            'quadrant_extremes_table': table_md,
            'quadrant_distribution_chart_path': chart_filename,
            'quadrant_extremes_footnote_ref': footnote_ref
        }
    except Exception as e:
        update_status(status_widget, f"ERROR during quadrant extremes analysis: {e}")
        return None




def generate_board_halves_extremes_analysis(df, status_widget, footnote_manager):
    """
    Generates a table for the min/max board half usage and their source games.

    Args:
        df (pd.DataFrame): The main dataframe with all game stats.
        status_widget: The tkinter widget for status updates.
        footnote_manager (FootnoteManager): The manager for creating footnotes.

    Returns:
        A dictionary containing markdown elements for the template, or None if an error occurs.
    """
    update_status(status_widget, "Generating board halves extremes analysis...")
    try:
        half_info = {
            'top_half_perc': 'Top Half',
            'bottom_half_perc': 'Bottom Half',
            'left_half_perc': 'Left Half',
            'right_half_perc': 'Right Half'
        }
        half_perc_cols = list(half_info.keys())

        # --- Check for required columns ---
        if not all(col in df.columns for col in half_perc_cols):
            update_status(status_widget, f"ERROR: CSV is missing one of {half_perc_cols}.")
            update_status(status_widget, "Please re-run 'Gather Stats' with the new BoardHalvesStatistic.")
            return None

        # --- Generate the simple table using to_markdown ---
        mins = df[half_perc_cols].min()
        maxs = df[half_perc_cols].max()
        table_df = pd.DataFrame({
            'Board Half': list(half_info.values()),
            'Min Usage (%)': mins.values,
            'Max Usage (%)': maxs.values
        })
        table_md = table_df.to_markdown(index=False, floatfmt=".2f")

        # --- Find all source games and build a single footnote string ---
        footnote_lines = []
        for col, name in half_info.items():
            min_idx = df[col].idxmin()
            min_game = df.loc[min_idx, 'game_id']
            footnote_lines.append(f"| Min usage for {name}: **{min_game}**")

            max_idx = df[col].idxmax()
            max_game = df.loc[max_idx, 'game_id']
            footnote_lines.append(f"| Max usage for {name}: **{max_game}**")
        
        full_footnote_text = "\n" + "\n".join(footnote_lines)
        footnote_ref = footnote_manager.add_footnote(full_footnote_text)

        update_status(status_widget, "Board halves extremes analysis complete.")
        return {
            'board_halves_extremes_table': table_md,
            'board_halves_extremes_footnote_ref': footnote_ref
        }
    except Exception as e:
        update_status(status_widget, f"ERROR during board halves extremes analysis: {e}")
        return None
    






def start_report_generation(status_widget):
    """Orchestrator function called by the 'Generate Report' button."""
    # This function can be expanded to take options for which report to generate
    generate_analysis_report(status_widget)



    


# =================================================================================================
# /////////////////////////////////////////////////////////////////////////////////////////////////
# --- MAIN EXECUTION ---
# /////////////////////////////////////////////////////////////////////////////////////////////////
# =================================================================================================

if __name__ == "__main__":
    setup_gui()
